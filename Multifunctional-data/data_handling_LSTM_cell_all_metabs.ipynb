{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib\n",
    "\n",
    "import timeit\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version==3.7.9\n",
      "pandas==1.2.2\n",
      "numpy==1.19.2\n",
      "sklearn==0.24.1\n",
      "torch==1.9.0\n",
      "matplotlib==3.3.4\n"
     ]
    }
   ],
   "source": [
    "print(\"python version==%s\" % python_version())\n",
    "print(\"pandas==%s\" % pd.__version__)\n",
    "print(\"numpy==%s\" % np.__version__)\n",
    "print(\"sklearn==%s\" % sklearn.__version__)\n",
    "print(\"torch==%s\" % torch.__version__)\n",
    "print(\"matplotlib==%s\" % matplotlib.__version__)\n",
    "\n",
    "plt.rcParams[\n",
    "    \"figure.facecolor\"\n",
    "] = \"w\"  # force white background on plots when using dark mode in JupyterLab\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms_training=[ 'PC-BV-BT-BC-BP-EL-FP-CH-AC-BH-CG-ER-RI-DF',\n",
    "                 'BV-BF-BO-BT-BU-DP-BL-BA-BP-EL-FP-CH-AC-BH-CG-ER-RI',\n",
    "                 'PJ-BO-BT-BC-BY-BA-CA-EL-FP-CH-AC-BH-CG-CC-DF',\n",
    "                 'PC-PJ-BF-BO-BU-DP-BA-EL-CH-BH-CG',\n",
    "                 'PC-PJ-BV-BF-BT-BL-CA-EL-FP-CH-BH-CC-DF',\n",
    "                 'PJ-BC-BY-BA-CA-EL-FP-AC-ER-CC-DF',\n",
    "                 'PJ-BV-BO-BT-BY-BU-CA-EL-AC-CG-DF',\n",
    "                 'PC-PJ-BT-BY-BU-DP-BA-CA-FP-CH-BH-CG-ER-RI-CC-DL-DF',\n",
    "                 'BV-BU-DP-BA-CA-EL-FP-CH-CG-RI-DL-DF',\n",
    "                 'PC-PJ-BF-BC-BU-DP-CA-EL-FP-CH-AC-CG',\n",
    "                 'BO-BC-BY-BU-BA-BP-CH-AC-CG-CC-DL',\n",
    "                 'PC-BV-BF-BT-BL-CA-CH-BH-CG-ER-RI-CC-DL',\n",
    "                 'BC-BU-DP-BL-BP-CA-EL-FP-BH-DL-DF',\n",
    "                 'PJ-BF-BC-BU-BP-CA-EL-FP-CH-AC-CG',\n",
    "                 'BO-BC-BY-BU-BA-CA-EL-AC-RI-DL-DF',\n",
    "                 'BV-BF-BY-BU-DP-BL-CA-EL-CH-BH-ER',\n",
    "                 'BV-BF-BC-BY-BU-DP-BL-EL-CH-AC-CG',\n",
    "                 'PJ-BF-DP-BL-BA-BP-CA-EL-BH-ER-DF',\n",
    "                 'PJ-BV-BF-BT-BC-BY-BU-CH-AC-RI-DF',\n",
    "                 'PC-PJ-BC-BY-BU-CA-EL-AC-BH-ER-RI',\n",
    "                 'BY-BU-BP-CA-EL-FP-AC-BH-CG-ER-RI',\n",
    "                 'PJ-BV-BF-BO-BU-DP-BL-CA-EL-FP-CH-AC',\n",
    "                 'PC-BF-BO-BT-BC-BU-BP-CA-EL-AC-BH-RI',\n",
    "                 'BF-BT-BC-BY-BL-BA-BP-EL-FP-AC-BH-CG-ER',\n",
    "                 'PC-BF-BT-BC-BU-DP-BL-BA-FP-AC-CC-DL-DF',\n",
    "                 'BC-BU-DP-BA-BP-CA-FP-CG-RI-CC-DF',\n",
    "                 'PC-PJ-BV-BO-BC-BY-DP-BL-BA-BP-CA-EL-AC-BH-CG-ER-RI',\n",
    "                 'PC-PJ-BV-BO-BY-BU-DP-BL-CA-EL-FP-CH-BH-CG-CC-DL',\n",
    "                 'BV-BF-BL-CA-FP-CH-AC-BH-ER-RI-DF',\n",
    "                 'PC-PJ-BO-BT-BC-BL-EL-FP-BH-CG-RI-DL',\n",
    "                 'PJ-BV-BO-BC-BU-DP-BL-EL-CH-CG-RI',\n",
    "                 'PC-PJ-BF-BT-BC-BY-DP-BL-BA-FP-AC-BH-RI-CC-DL-DF',\n",
    "                 'PC-PJ-BV-BF-BT-BC-DP-CA-EL-CH-AC-BH-CG-RI-DF',\n",
    "                 'BF-BU-DP-BL-BA-CA-EL-FP-AC-CG-RI',\n",
    "                 'PC-BV-BF-BO-BC-DP-BL-EL-CH-BH-CG-RI',\n",
    "                 'PC-BV-BF-BO-CA-EL-FP-CH-AC-BH-ER',\n",
    "                 'PJ-BV-BY-BA-EL-FP-CH-BH-ER-DL-DF',\n",
    "                 'PJ-BV-BF-BU-DP-BL-BA-EL-RI-DL-DF',\n",
    "                 'BV-BO-BC-BY-BL-BA-FP-AC-BH-CG-DL-DF',\n",
    "                 'PJ-BY-BU-EL-FP-CH-AC-BH-CG-CC-DF',\n",
    "                 'PC-PJ-BO-BT-BL-BP-CH-AC-BH-CG-CC-DF',\n",
    "                 'PJ-BO-BT-BU-BP-CA-EL-CH-AC-BH-RI',\n",
    "                 'PC-PJ-BF-BU-DP-BA-CA-FP-CH-AC-RI-CC-DL',\n",
    "                 'PJ-BV-BO-BT-BY-BU-DP-BL-CA-BH-CG-ER-CC-DL',\n",
    "                 'BV-BF-BO-BY-BU-DP-CA-EL-CH-RI-DF',\n",
    "                 'BF-BO-BT-BC-BU-CA-EL-AC-ER-RI-DF',\n",
    "                 'PJ-BF-BC-BU-BA-BP-CA-EL-AC-BH-DL',\n",
    "                 'PC-PJ-BV-BF-DP-EL-FP-CH-AC-ER-CC-DF',\n",
    "                 'PC-PJ-BT-BC-BU-DP-BL-BP-CA-EL-RI-CC-DF',\n",
    "                 'PC-BF-BT-BC-BU-DP-BL-CH-BH-RI-CC',\n",
    "                 'PC-PJ-BV-BT-BC-BA-CA-CH-AC-ER-RI-CC-DL',\n",
    "                 'BF-BO-BC-BL-CA-EL-BH-CG-RI-CC-DL',\n",
    "                 'BY-BU-DP-BL-CA-EL-CH-BH-CG-CC-DF',\n",
    "                 'PJ-BV-BF-BT-BC-BY-DP-CH-AC-BH-CC-DF',\n",
    "                 'PC-PJ-BF-BT-BC-BU-DP-BL-CH-AC-BH-CG-RI-DF',\n",
    "                 'PJ-BV-BO-BT-BC-BY-BP-CA-EL-FP-AC-BH-CG',\n",
    "                 'PJ-BC-BP-EL-FP-AC-BH-ER-RI-CC-DF',\n",
    "                 'BV-BO-BC-BU-DP-BP-EL-FP-AC-RI-DL-DF',\n",
    "                 'PC-BF-BO-BU-BA-BP-CA-FP-CG-CC-DL-DF',\n",
    "                 'BC-BU-BL-CA-EL-FP-AC-ER-RI-CC-DL']\n",
    "\n",
    "comms_validation=[   'PC-PJ-BV-BF-BC-BY-BU-DP-BL-BA-BP-CA-FP-BH-ER-RI-CC-DL-DF',\n",
    "                     'PC-PJ-BV-BO-BC-BY-BU-BP-EL-FP-AC-BH-CG-ER',\n",
    "                     'PC-BV-BF-BY-BU-EL-FP-CH-AC-ER-DF',\n",
    "                     'PC-BF-BO-BT-BC-BY-DP-BL-BP-CA-FP-CH-AC-BH-ER-RI-DL-DF',\n",
    "                     'BF-BC-BY-BA-CA-EL-FP-CH-AC-BH-ER-CC-DL-DF',\n",
    "                     'BV-BO-BT-BY-BL-BA-BP-EL-FP-AC-BH-DL-DF',\n",
    "                     'PC-PJ-BV-BF-BY-BU-BA-EL-FP-CH-AC-CG-RI',\n",
    "                     'PC-PJ-BV-BO-BT-BY-BA-BP-EL-FP-CH-CG-DL',\n",
    "                     'PC-PJ-BL-BA-BP-CA-EL-FP-CH-AC-ER-RI',\n",
    "                     'PC-PJ-BF-BY-DP-BA-CA-CG-RI-CC-DL',\n",
    "                     'PC-BO-BC-BU-DP-BL-CA-AC-BH-CG-RI-CC-DF',\n",
    "                     'PC-PJ-BF-BO-BY-BU-AC-BH-RI-DL-DF',\n",
    "                     'PJ-BV-BF-BO-BT-BC-BU-BA-CA-BH-ER-CC-DF',\n",
    "                     'PC-PJ-BV-BO-BC-BU-BL-BA-CA-FP-CH-BH-CG-CC',\n",
    "                     'PC-PJ-BC-BU-BL-BP-CA-EL-FP-AC-CG-DL',\n",
    "                     'PJ-BF-BO-BU-BA-CA-EL-CH-BH-CG-RI-CC-DL',\n",
    "                     'PC-BF-BT-DP-BL-CA-CH-AC-CG-ER-DF',\n",
    "                     'PC-PJ-BV-BF-BY-BA-BP-CA-EL-BH-CG-ER-DL',\n",
    "                     'PC-PJ-BO-BT-BC-BY-FP-CH-AC-ER-RI-DL-DF',\n",
    "                     'BF-BO-BC-BY-BU-DP-BA-BP-FP-CH-AC-BH-ER-RI-CC-DL-DF',\n",
    "                     'PJ-BV-BO-BU-CA-CH-AC-BH-CG-RI-DL-DF',\n",
    "                     'PC-BF-BO-BC-BY-DP-BL-BA-BP-CA-EL-AC-BH-CG-RI-CC-DL',\n",
    "                     'PJ-BO-BT-BC-CA-EL-FP-AC-BH-ER-RI',\n",
    "                     'PJ-BO-BT-BC-BY-BU-BL-BP-FP-AC-BH-CG-RI-DF',\n",
    "                     'PC-PJ-BC-BY-DP-BL-CA-FP-CH-BH-ER-RI',\n",
    "                     'BF-BU-BL-BA-EL-FP-CH-BH-CG-RI-DL',\n",
    "                     'PC-PJ-BO-BC-BY-BU-DP-BL-CA-EL-CH-AC-BH-CG-DL-DF',\n",
    "                     'PC-PJ-BV-BF-BO-BU-CA-CH-AC-BH-CG',\n",
    "                     'PJ-BV-BT-BC-BY-BU-DP-BA-BP-CH-AC-CG-CC-DF',\n",
    "                     'PC-BT-BC-BY-DP-BL-BA-CA-FP-CH-BH-CG-ER-RI',\n",
    "                     'PC-PJ-BF-BO-BU-DP-BA-CA-EL-FP-CH-AC-BH-ER-CC-DL-DF',\n",
    "                     'PC-BV-BF-BO-BT-BU-DP-CA-EL-FP-BH-CG-DF',\n",
    "                     'PJ-BF-BO-BT-BC-BY-BU-DP-BL-BA-CH-AC-CG-RI-CC-DF',\n",
    "                     'PJ-BV-BO-BU-CA-EL-FP-CH-BH-CG-ER',\n",
    "                     'PC-PJ-BV-BF-BO-BT-BC-BY-BU-DP-BL-BA-BP-CA-EL-FP-CH-AC-BH-CG-ER-RI-CC-DL-DF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are , Community, Time, Richness, Contamination, PC, PC_OD, PJ, PJ_OD, BV, BV_OD, BF, BF_OD, BO, BO_OD, BT, BT_OD, BC, BC_OD, BY, BY_OD, BU, BU_OD, DP, DP_OD, BL, BL_OD, BA, BA_OD, BP, BP_OD, CA, CA_OD, EL, EL_OD, FP, FP_OD, CH, CH_OD, AC, AC_OD, BH, BH_OD, CG, CG_OD, ER, ER_OD, RI, RI_OD, CC, CC_OD, DL, DL_OD, DF, DF_OD, OD, Butyrate, Acetate, Lactate, Succinate\n",
      "Processed 381 lines.\n"
     ]
    }
   ],
   "source": [
    "train_abundance = {}\n",
    "test_abundance  = {}\n",
    "\n",
    "buty_train  = {}\n",
    "ace_train   = {}\n",
    "lac_train   = {}\n",
    "succ_train  = {}\n",
    "\n",
    "buty_test   = {}\n",
    "ace_test    = {}\n",
    "lac_test    = {}\n",
    "succ_test   = {}\n",
    "\n",
    "with open('2021_02_19_MultifunctionalDynamicData.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    four_count = 1\n",
    "    butyrate, acetate, lactate, succinate = [], [], [], []\n",
    "    abundance_data                        = []\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "        else:\n",
    "            comm  = row[1]\n",
    "            time  = float(row[2])\n",
    "            PC_OD = float(row[6])\n",
    "            PJ_OD = float(row[8])\n",
    "            BV_OD = float(row[10])\n",
    "            BF_OD = float(row[12])\n",
    "            BO_OD = float(row[14])\n",
    "            BT_OD = float(row[16])\n",
    "            BC_OD = float(row[18])\n",
    "            BY_OD = float(row[20])\n",
    "            BU_OD = float(row[22])\n",
    "            DP_OD = float(row[24])\n",
    "            BL_OD = float(row[26])\n",
    "            BA_OD = float(row[28])\n",
    "            BP_OD = float(row[30])\n",
    "            CA_OD = float(row[32])\n",
    "            EL_OD = float(row[34])\n",
    "            FP_OD = float(row[36])\n",
    "            CH_OD = float(row[38])\n",
    "            AC_OD = float(row[40])\n",
    "            BH_OD = float(row[42])\n",
    "            CG_OD = float(row[44])\n",
    "            ER_OD = float(row[46])\n",
    "            RI_OD = float(row[48])\n",
    "            CC_OD = float(row[50])\n",
    "            DL_OD = float(row[52])\n",
    "            DF_OD = float(row[54])\n",
    "            buty  = float(row[56])\n",
    "            ace   = float(row[57])\n",
    "            lac   = float(row[58])\n",
    "            succ  = float(row[59])\n",
    "            \n",
    "            butyrate.append(buty)\n",
    "            acetate.append(ace)\n",
    "            lactate.append(lac)\n",
    "            succinate.append(succ)\n",
    "            \n",
    "            abundance_data.append([PC_OD, PJ_OD, BV_OD, BF_OD, BO_OD, BT_OD, \\\n",
    "                                   BC_OD, BY_OD, BU_OD, DP_OD, BL_OD, BA_OD, \\\n",
    "                                   BP_OD, CA_OD, EL_OD, FP_OD, CH_OD, AC_OD, \\\n",
    "                                   BH_OD, CG_OD, ER_OD, RI_OD, CC_OD, DL_OD, DF_OD])\n",
    "            \n",
    "            if comm in comms_training:\n",
    "                is_train = True\n",
    "            else:\n",
    "                is_train = False\n",
    "                \n",
    "            if is_train:\n",
    "                if comm not in train_abundance.keys():\n",
    "                    train_abundance[comm] = []\n",
    "                    buty_train[comm]      = []\n",
    "                    ace_train[comm]       = []\n",
    "                    lac_train[comm]       = []\n",
    "                    succ_train[comm]      = []\n",
    "            else:\n",
    "                if comm not in test_abundance.keys():\n",
    "                    test_abundance[comm] = []\n",
    "                    buty_test[comm]      = []\n",
    "                    ace_test[comm]       = []\n",
    "                    lac_test[comm]       = []\n",
    "                    succ_test[comm]      = []\n",
    "            \n",
    "            if four_count == 4:\n",
    "                if is_train:\n",
    "                    train_abundance[comm] = np.array(abundance_data)\n",
    "                    buty_train[comm]      = np.array(butyrate)\n",
    "                    ace_train[comm]       = np.array(acetate)\n",
    "                    lac_train[comm]       = np.array(lactate)\n",
    "                    succ_train[comm]      = np.array(succinate)\n",
    "                else:\n",
    "                    test_abundance[comm]  = np.array(abundance_data)\n",
    "                    buty_test[comm]       = np.array(butyrate)\n",
    "                    ace_test[comm]        = np.array(acetate)\n",
    "                    lac_test[comm]        = np.array(lactate)\n",
    "                    succ_test[comm]       = np.array(succinate)\n",
    "                \n",
    "                four_count = 1\n",
    "                abundance_data                        = []\n",
    "                butyrate, acetate, lactate, succinate = [], [], [], []\n",
    "            else:\n",
    "                four_count += 1\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abundance_data = np.zeros((len(train_abundance),4,25))\n",
    "test_abundance_data  = np.zeros((len(test_abundance),4,25))\n",
    "\n",
    "train_butyrate  = np.zeros((len(train_abundance),4,1))\n",
    "train_acetate   = np.zeros((len(train_abundance),4,1))\n",
    "train_lactate   = np.zeros((len(train_abundance),4,1))\n",
    "train_succinate = np.zeros((len(train_abundance),4,1))\n",
    "\n",
    "test_butyrate   = np.zeros((len(test_abundance),4,1))\n",
    "test_acetate    = np.zeros((len(test_abundance),4,1))\n",
    "test_lactate    = np.zeros((len(test_abundance),4,1))\n",
    "test_succinate  = np.zeros((len(test_abundance),4,1))\n",
    "\n",
    "for no, comm in enumerate(train_abundance):\n",
    "    train_abundance_data[no] = train_abundance[comm].reshape(1,4,25)\n",
    "    train_butyrate[no]       = buty_train[comm].reshape(1,4,1)\n",
    "    train_acetate[no]        = ace_train[comm].reshape(1,4,1)\n",
    "    train_lactate[no]        = lac_train[comm].reshape(1,4,1)\n",
    "    train_succinate[no]      = succ_train[comm].reshape(1,4,1)\n",
    "    \n",
    "for no, comm in enumerate(test_abundance):\n",
    "    test_abundance_data[no]  = test_abundance[comm].reshape(1,4,25)\n",
    "    test_butyrate[no]        = buty_test[comm].reshape(1,4,1)\n",
    "    test_acetate[no]         = ace_test[comm].reshape(1,4,1)\n",
    "    test_lactate[no]         = lac_test[comm].reshape(1,4,1)\n",
    "    test_succinate[no]       = succ_test[comm].reshape(1,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_all = False  #Normalize with respect to the entire dataset\n",
    "\n",
    "seq_len = 3\n",
    "\n",
    "#Concatenating for data normalization\n",
    "X_abundance   = np.concatenate((train_abundance_data,test_abundance_data), axis=0)\n",
    "X_buty        = np.concatenate((train_butyrate,test_butyrate), axis=0)\n",
    "X_ace         = np.concatenate((train_acetate,test_acetate), axis=0)\n",
    "X_lac         = np.concatenate((train_lactate,test_lactate), axis=0)\n",
    "X_succ        = np.concatenate((train_succinate,test_succinate), axis=0)\n",
    "\n",
    "if normalize_all:\n",
    "    X_abun_metab  = np.concatenate((X_abundance, X_buty, X_ace, X_lac, X_succ), axis=2)\n",
    "else:\n",
    "    X_abun_metab  = np.concatenate((train_abundance_data, train_butyrate, train_acetate, train_lactate, train_succinate), axis=2)\n",
    "    \n",
    "Xm_abun_metab = np.mean(X_abun_metab,0)\n",
    "Xv_abun_metab = 4*np.std(X_abun_metab,0)\n",
    "Xv_abun_metab[Xv_abun_metab == 0] = 1.\n",
    "\n",
    "training_data = np.concatenate((train_abundance_data, train_butyrate, train_acetate, train_lactate, train_succinate), axis=2)\n",
    "testing_data  = np.concatenate((test_abundance_data, test_butyrate, test_acetate, test_lactate, test_succinate), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm_train = np.tile(Xm_abun_metab,(train_abundance_data.shape[0],1,1))\n",
    "Xv_train = np.tile(Xv_abun_metab,(train_abundance_data.shape[0],1,1))\n",
    "\n",
    "Xm_test  = np.tile(Xm_abun_metab,(test_abundance_data.shape[0],1,1))\n",
    "Xv_test  = np.tile(Xv_abun_metab,(test_abundance_data.shape[0],1,1))\n",
    "\n",
    "train_data_red = (training_data - Xm_train)/Xv_train\n",
    "test_data_red  = (testing_data - Xm_test)/Xv_test\n",
    "\n",
    "X_train, Y_train = train_data_red[:,:-1,:], train_data_red[:,1:,:]\n",
    "X_test, Y_test   = test_data_red[:,:-1,:], test_data_red[:,1:,:]\n",
    "\n",
    "x_train, y_train = torch.from_numpy(X_train).float().to(device), torch.from_numpy(Y_train).float().to(device)\n",
    "x_test, y_test   = torch.from_numpy(X_test).float().to(device), torch.from_numpy(Y_test).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm        = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "        self.linear      = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, inputs, future=0, y=None):\n",
    "        outputs = []\n",
    "        batch_size = inputs\n",
    "\n",
    "        # reset the state of LSTM\n",
    "        h_t = torch.zeros(inputs.size(0), self.hidden_size, dtype=torch.float32).to(device)\n",
    "        c_t = torch.zeros(inputs.size(0), self.hidden_size, dtype=torch.float32).to(device)\n",
    "\n",
    "        for i, input_t in enumerate(inputs.chunk(inputs.size(1), dim=1)):\n",
    "            h_t, c_t   = self.lstm(torch.squeeze(input_t,1), (h_t, c_t))\n",
    "            output     = self.linear(h_t)\n",
    "            outputs   += [output]\n",
    "            \n",
    "        for i in range(future):\n",
    "            if y is not None and random.random() > 0.5:\n",
    "                output = torch.squeeze(y[:,[i],:], 1)  # teacher forcing\n",
    "            h_t, c_t   = self.lstm(output, (h_t, c_t))\n",
    "            output     = self.linear(h_t)\n",
    "            outputs   += [output]\n",
    "            \n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 10\n",
    "lr             = 5e-3\n",
    "lr_decay       = 0.25\n",
    "decay_interval = 12\n",
    "iteration      = 200\n",
    "\n",
    "batch_size, decay_interval, iteration = map(int, [batch_size, decay_interval, iteration])\n",
    "lr, lr_decay                          = map(float, [lr, lr_decay])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data(x, y, batch_size):\n",
    "    for batch, i in enumerate(range(0, len(x), batch_size)):\n",
    "        x_batch     = x[i : i + batch_size]\n",
    "        y_batch     = y[i : i + batch_size]\n",
    "        yield x_batch, y_batch, batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x_batch, y_batch, seq_len, do_teacher_forcing):\n",
    "    b_size = x_batch.size(0)\n",
    "    f_size = x_batch.size(2)\n",
    "    \n",
    "    if do_teacher_forcing:\n",
    "        future = random.randint(1, int(seq_len) // 2)\n",
    "        limit  = x_batch.size(1) - future\n",
    "        y_pred = model(x_batch[:, :limit].view(b_size,-1,f_size), future=future, y=y_batch[:, limit:].view(b_size,-1,f_size))\n",
    "    else:\n",
    "        future = 0\n",
    "        y_pred = model(x_batch)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b133f9ff11e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdir_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'output/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "model   = Model(29,4096,29).to(device)\n",
    "\n",
    "stop\n",
    "dir_output = ('output/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "dir_output = ('output/Abundance/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "dir_output = ('output/Metabolites/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "dir_output = ('output/Community/Abundance/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "dir_output = ('output/Community/Metabolites/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "dir_output = ('output/heatmap/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "loss_fn   = nn.MSELoss()\n",
    "\n",
    "print('Training...')\n",
    "print('Epoch \\t Time(sec) \\t Loss_train \\t Loss_test \\t Learning_rate')\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "do_teacher_forcing = True\n",
    "for epoch in range(iteration):\n",
    "    if (epoch+1) % decay_interval == 0:\n",
    "        if epoch <= 99:\n",
    "            optimizer.param_groups[0]['lr'] *= lr_decay\n",
    "\n",
    "    futures = []\n",
    "    \n",
    "    train_loss = 0\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
    "        y_pred = predict(model, x_batch, y_batch, seq_len, do_teacher_forcing)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    actual, predicted = [], []\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_test[:,0:1,:], y_test, batch_size):\n",
    "        y_pred = model(x_batch, future=seq_len-1)\n",
    "        y_pred = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "        actual += torch.squeeze(y_batch[:, -1]).data.cpu().numpy().tolist()\n",
    "        predicted += torch.squeeze(y_pred[:, -1]).data.cpu().numpy().tolist()\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    lr_rate = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    end  = timeit.default_timer()\n",
    "    time = end - start\n",
    "\n",
    "    print('%d \\t %.4f \\t %.4f \\t %.4f \\t %.6f' %(epoch, time, train_loss, test_loss, lr_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67735581"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.zeros(3,3)\n",
    "A[:, 0] = torch.tensor(np.array([3,3,3]), dtype=torch.float32)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting abundance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_to_study in range(seq_len):\n",
    "    for is_train in list([True, False]):\n",
    "        \n",
    "        Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "        Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "        model.eval()\n",
    "        actual, predicted = [], []\n",
    "\n",
    "        if is_train:\n",
    "            for x_batch, y_batch, batch in generate_batch_data(x_train[:,0:1,:], y_train, batch_size):\n",
    "                y_pred     = model(x_batch, future=seq_len-1)\n",
    "                y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "                actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "                predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "                plt_str    = 'Training'\n",
    "        else:\n",
    "            for x_batch, y_batch, batch in generate_batch_data(x_test[:,0:1,:], y_test, batch_size):\n",
    "                y_pred     = model(x_batch, future=seq_len-1)\n",
    "                y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "                actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "                predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "                plt_str    = 'Testing'\n",
    "\n",
    "        act_arr  = np.array(actual)\n",
    "        pred_arr = np.array(predicted)\n",
    "        \n",
    "        Act  = (act_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "        Pred = (pred_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "        Pred[Pred<0] = 0.\n",
    "\n",
    "        slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "        print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "        x_vals = np.linspace(min(Act),max(Act),50)\n",
    "        y_vals = slope*x_vals + intercept\n",
    "\n",
    "        params = {'legend.fontsize': 24,\n",
    "                  'figure.figsize' : (10, 10),\n",
    "                 'axes.labelsize'  : 24,\n",
    "                 'axes.titlesize'  : 24,\n",
    "                 'xtick.labelsize' : 22,\n",
    "                 'ytick.labelsize' : 22,\n",
    "                 'pdf.fonttype'    : 42}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "        plt.plot(Act, Pred, 'or')\n",
    "        plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "        plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "        plt.xlabel('True values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.legend(['Predicted abundance','Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "        plt.savefig('output/Abundance/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Metabolite Concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metab_list = ['Butyrate', 'Acetate', 'Lactate', 'Succinate']\n",
    "\n",
    "for no, metab_name in enumerate(metab_list):\n",
    "    metab_ind = no-4\n",
    "    \n",
    "    for ind_to_study in range(seq_len):\n",
    "        for is_train in list([True, False]):\n",
    "\n",
    "            Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "            Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "            model.eval()\n",
    "            actual, predicted = [], []\n",
    "\n",
    "            if is_train:\n",
    "                for x_batch, y_batch, batch in generate_batch_data(x_train[:,0:1,:], y_train, batch_size):\n",
    "                    y_pred     = model(x_batch, future=seq_len-1)\n",
    "                    y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "                    actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "                    predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "                    plt_str    = 'Training_' + metab_name\n",
    "            else:\n",
    "                for x_batch, y_batch, batch in generate_batch_data(x_test[:,0:1,:], y_test, batch_size):\n",
    "                    y_pred     = model(x_batch, future=seq_len-1)\n",
    "                    y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "                    actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().tolist()\n",
    "                    predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().tolist()\n",
    "                    plt_str    = 'Testing_' + metab_name\n",
    "\n",
    "            act_arr  = np.array(actual)\n",
    "            pred_arr = np.array(predicted)\n",
    "\n",
    "            Act  = (act_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "            Pred = (pred_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "            Pred[Pred<0] = 0.\n",
    "\n",
    "            slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "            print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "            x_vals = np.linspace(min(Act),max(Act),50)\n",
    "            y_vals = slope*x_vals + intercept\n",
    "\n",
    "            params = {'legend.fontsize': 24,\n",
    "                      'figure.figsize' : (10, 10),\n",
    "                     'axes.labelsize'  : 24,\n",
    "                     'axes.titlesize'  : 24,\n",
    "                     'xtick.labelsize' : 22,\n",
    "                     'ytick.labelsize' : 22,\n",
    "                     'pdf.fonttype'    : 42}\n",
    "            plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "            plt.plot(Act, Pred, 'or')\n",
    "            plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "            plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "            plt.axis('equal')\n",
    "            plt.axis('square')\n",
    "            plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "            plt.xlabel('True values')\n",
    "            plt.ylabel('Predicted values')\n",
    "            plt.legend(['Predicted concentration_' + metab_name,'Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "            plt.savefig('output/Metabolites/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community-wise performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderlist=['PC-BV-BT-BC-BP-EL-FP-CH-AC-BH-CG-ER-RI-DF', \n",
    "           'BV-BF-BO-BT-BU-DP-BL-BA-BP-EL-FP-CH-AC-BH-CG-ER-RI', \n",
    "           'PJ-BO-BT-BC-BY-BA-CA-EL-FP-CH-AC-BH-CG-CC-DF', \n",
    "           'PC-PJ-BF-BO-BU-DP-BA-EL-CH-BH-CG', \n",
    "           'PC-PJ-BV-BF-BT-BL-CA-EL-FP-CH-BH-CC-DF', \n",
    "           'PJ-BC-BY-BA-CA-EL-FP-AC-ER-CC-DF', \n",
    "           'PJ-BV-BO-BT-BY-BU-CA-EL-AC-CG-DF', \n",
    "           'PC-PJ-BT-BY-BU-DP-BA-CA-FP-CH-BH-CG-ER-RI-CC-DL-DF', \n",
    "           'BV-BU-DP-BA-CA-EL-FP-CH-CG-RI-DL-DF', \n",
    "           'PC-PJ-BF-BC-BU-DP-CA-EL-FP-CH-AC-CG', \n",
    "           'BO-BC-BY-BU-BA-BP-CH-AC-CG-CC-DL', \n",
    "           'PC-BV-BF-BT-BL-CA-CH-BH-CG-ER-RI-CC-DL', \n",
    "           'BC-BU-DP-BL-BP-CA-EL-FP-BH-DL-DF', \n",
    "           'PJ-BF-BC-BU-BP-CA-EL-FP-CH-AC-CG', \n",
    "           'BO-BC-BY-BU-BA-CA-EL-AC-RI-DL-DF', \n",
    "           'BV-BF-BY-BU-DP-BL-CA-EL-CH-BH-ER', \n",
    "           'BV-BF-BC-BY-BU-DP-BL-EL-CH-AC-CG', \n",
    "           'PJ-BF-DP-BL-BA-BP-CA-EL-BH-ER-DF', \n",
    "           'PJ-BV-BF-BT-BC-BY-BU-CH-AC-RI-DF', \n",
    "           'PC-PJ-BC-BY-BU-CA-EL-AC-BH-ER-RI', \n",
    "           'BY-BU-BP-CA-EL-FP-AC-BH-CG-ER-RI', \n",
    "           'PJ-BV-BF-BO-BU-DP-BL-CA-EL-FP-CH-AC', \n",
    "           'PC-BF-BO-BT-BC-BU-BP-CA-EL-AC-BH-RI', \n",
    "           'BF-BT-BC-BY-BL-BA-BP-EL-FP-AC-BH-CG-ER', \n",
    "           'PC-BF-BT-BC-BU-DP-BL-BA-FP-AC-CC-DL-DF', \n",
    "           'BC-BU-DP-BA-BP-CA-FP-CG-RI-CC-DF', \n",
    "           'PC-PJ-BV-BO-BC-BY-DP-BL-BA-BP-CA-EL-AC-BH-CG-ER-RI', \n",
    "           'PC-PJ-BV-BO-BY-BU-DP-BL-CA-EL-FP-CH-BH-CG-CC-DL', \n",
    "           'BV-BF-BL-CA-FP-CH-AC-BH-ER-RI-DF', \n",
    "           'PC-PJ-BO-BT-BC-BL-EL-FP-BH-CG-RI-DL', \n",
    "           'PJ-BV-BO-BC-BU-DP-BL-EL-CH-CG-RI', \n",
    "           'PC-PJ-BF-BT-BC-BY-DP-BL-BA-FP-AC-BH-RI-CC-DL-DF', \n",
    "           'PC-PJ-BV-BF-BT-BC-DP-CA-EL-CH-AC-BH-CG-RI-DF', \n",
    "           'BF-BU-DP-BL-BA-CA-EL-FP-AC-CG-RI', \n",
    "           'PC-BV-BF-BO-BC-DP-BL-EL-CH-BH-CG-RI', \n",
    "           'PC-BV-BF-BO-CA-EL-FP-CH-AC-BH-ER', \n",
    "           'PJ-BV-BY-BA-EL-FP-CH-BH-ER-DL-DF', \n",
    "           'PJ-BV-BF-BU-DP-BL-BA-EL-RI-DL-DF', \n",
    "           'BV-BO-BC-BY-BL-BA-FP-AC-BH-CG-DL-DF', \n",
    "           'PJ-BY-BU-EL-FP-CH-AC-BH-CG-CC-DF', \n",
    "           'PC-PJ-BO-BT-BL-BP-CH-AC-BH-CG-CC-DF', \n",
    "           'PJ-BO-BT-BU-BP-CA-EL-CH-AC-BH-RI', \n",
    "           'PC-PJ-BF-BU-DP-BA-CA-FP-CH-AC-RI-CC-DL', \n",
    "           'PJ-BV-BO-BT-BY-BU-DP-BL-CA-BH-CG-ER-CC-DL', \n",
    "           'BV-BF-BO-BY-BU-DP-CA-EL-CH-RI-DF', \n",
    "           'BF-BO-BT-BC-BU-CA-EL-AC-ER-RI-DF', \n",
    "           'PJ-BF-BC-BU-BA-BP-CA-EL-AC-BH-DL', \n",
    "           'PC-PJ-BV-BF-DP-EL-FP-CH-AC-ER-CC-DF', \n",
    "           'PC-PJ-BT-BC-BU-DP-BL-BP-CA-EL-RI-CC-DF', \n",
    "           'PC-BF-BT-BC-BU-DP-BL-CH-BH-RI-CC', \n",
    "           'PC-PJ-BV-BT-BC-BA-CA-CH-AC-ER-RI-CC-DL', \n",
    "           'BF-BO-BC-BL-CA-EL-BH-CG-RI-CC-DL', \n",
    "           'BY-BU-DP-BL-CA-EL-CH-BH-CG-CC-DF', \n",
    "           'PJ-BV-BF-BT-BC-BY-DP-CH-AC-BH-CC-DF', \n",
    "           'PC-PJ-BF-BT-BC-BU-DP-BL-CH-AC-BH-CG-RI-DF', \n",
    "           'PJ-BV-BO-BT-BC-BY-BP-CA-EL-FP-AC-BH-CG', \n",
    "           'PJ-BC-BP-EL-FP-AC-BH-ER-RI-CC-DF', \n",
    "           'BV-BO-BC-BU-DP-BP-EL-FP-AC-RI-DL-DF', \n",
    "           'PC-BF-BO-BU-BA-BP-CA-FP-CG-CC-DL-DF', \n",
    "           'BC-BU-BL-CA-EL-FP-AC-ER-RI-CC-DL', \n",
    "           'PC-PJ-BV-BF-BC-BY-BU-DP-BL-BA-BP-CA-FP-BH-ER-RI-CC-DL-DF', \n",
    "           'PC-PJ-BV-BO-BC-BY-BU-BP-EL-FP-AC-BH-CG-ER', \n",
    "           'PC-BV-BF-BY-BU-EL-FP-CH-AC-ER-DF', \n",
    "           'PC-BF-BO-BT-BC-BY-DP-BL-BP-CA-FP-CH-AC-BH-ER-RI-DL-DF', \n",
    "           'BF-BC-BY-BA-CA-EL-FP-CH-AC-BH-ER-CC-DL-DF', \n",
    "           'BV-BO-BT-BY-BL-BA-BP-EL-FP-AC-BH-DL-DF', \n",
    "           'PC-PJ-BV-BF-BY-BU-BA-EL-FP-CH-AC-CG-RI', \n",
    "           'PC-PJ-BV-BO-BT-BY-BA-BP-EL-FP-CH-CG-DL', \n",
    "           'PC-PJ-BL-BA-BP-CA-EL-FP-CH-AC-ER-RI', \n",
    "           'PC-PJ-BF-BY-DP-BA-CA-CG-RI-CC-DL', \n",
    "           'PC-BO-BC-BU-DP-BL-CA-AC-BH-CG-RI-CC-DF', \n",
    "           'PC-PJ-BF-BO-BY-BU-AC-BH-RI-DL-DF', \n",
    "           'PJ-BV-BF-BO-BT-BC-BU-BA-CA-BH-ER-CC-DF', \n",
    "           'PC-PJ-BV-BO-BC-BU-BL-BA-CA-FP-CH-BH-CG-CC', \n",
    "           'PC-PJ-BC-BU-BL-BP-CA-EL-FP-AC-CG-DL', \n",
    "           'PJ-BF-BO-BU-BA-CA-EL-CH-BH-CG-RI-CC-DL', \n",
    "           'PC-BF-BT-DP-BL-CA-CH-AC-CG-ER-DF', \n",
    "           'PC-PJ-BV-BF-BY-BA-BP-CA-EL-BH-CG-ER-DL', \n",
    "           'PC-PJ-BO-BT-BC-BY-FP-CH-AC-ER-RI-DL-DF', \n",
    "           'BF-BO-BC-BY-BU-DP-BA-BP-FP-CH-AC-BH-ER-RI-CC-DL-DF', \n",
    "           'PJ-BV-BO-BU-CA-CH-AC-BH-CG-RI-DL-DF', \n",
    "           'PC-BF-BO-BC-BY-DP-BL-BA-BP-CA-EL-AC-BH-CG-RI-CC-DL', \n",
    "           'PJ-BO-BT-BC-CA-EL-FP-AC-BH-ER-RI', \n",
    "           'PJ-BO-BT-BC-BY-BU-BL-BP-FP-AC-BH-CG-RI-DF', \n",
    "           'PC-PJ-BC-BY-DP-BL-CA-FP-CH-BH-ER-RI', \n",
    "           'BF-BU-BL-BA-EL-FP-CH-BH-CG-RI-DL', \n",
    "           'PC-PJ-BO-BC-BY-BU-DP-BL-CA-EL-CH-AC-BH-CG-DL-DF', \n",
    "           'PC-PJ-BV-BF-BO-BU-CA-CH-AC-BH-CG', \n",
    "           'PJ-BV-BT-BC-BY-BU-DP-BA-BP-CH-AC-CG-CC-DF', \n",
    "           'PC-BT-BC-BY-DP-BL-BA-CA-FP-CH-BH-CG-ER-RI', \n",
    "           'PC-PJ-BF-BO-BU-DP-BA-CA-EL-FP-CH-AC-BH-ER-CC-DL-DF', \n",
    "           'PC-BV-BF-BO-BT-BU-DP-CA-EL-FP-BH-CG-DF', \n",
    "           'PJ-BF-BO-BT-BC-BY-BU-DP-BL-BA-CH-AC-CG-RI-CC-DF', \n",
    "           'PJ-BV-BO-BU-CA-EL-FP-CH-BH-CG-ER',\n",
    "           'PC-PJ-BV-BF-BO-BT-BC-BY-BU-DP-BL-BA-BP-CA-EL-FP-CH-AC-BH-CG-ER-RI-CC-DL-DF']\n",
    "\n",
    "red_comm    = np.array([0, 1, 9, 10, 15, 16, 18, 21, 23, 24, 26, 31, 32, 38, 40, 42, 47, 50, 53, 54, 57, 63, 64, 65, 70, 72, 76, 78, 79, 80, 81, 83, 86, 88, 90, 92, 93, 94])\n",
    "blue_comm   = np.array([2, 35, 66, 41, 22, 55, 87, 28, 61, 62])\n",
    "green_comm  = np.array([3, 4, 7, 8, 11, 12, 17, 25, 27, 29, 30, 34, 36, 37, 43, 44, 48, 49, 51, 52, 58, 60, 67, 69, 73, 75, 77, 84, 85, 89, 91])\n",
    "purple_comm = np.array([68, 5, 39, 20, 56, 59])\n",
    "orange_comm = np.array([6, 45, 13, 82, 19])\n",
    "grey_comm   = np.array([33, 71, 74, 14, 46])\n",
    "\n",
    "red_comm_inds_train, red_comm_inds_val = [], []\n",
    "for ind in red_comm:\n",
    "    tmp = orderlist[ind]\n",
    "    if tmp in comms_training:\n",
    "        red_comm_inds_train.append(comms_training.index(tmp))\n",
    "    else:\n",
    "        red_comm_inds_val.append(comms_validation.index(tmp))\n",
    "\n",
    "\n",
    "blue_comm_inds_train, blue_comm_inds_val = [], []\n",
    "for ind in blue_comm:\n",
    "    tmp = orderlist[ind]\n",
    "    if tmp in comms_training:\n",
    "        blue_comm_inds_train.append(comms_training.index(tmp))\n",
    "    else:\n",
    "        blue_comm_inds_val.append(comms_validation.index(tmp))\n",
    "\n",
    "\n",
    "green_comm_inds_train, green_comm_inds_val = [], []\n",
    "for ind in green_comm:\n",
    "    tmp = orderlist[ind]\n",
    "    if tmp in comms_training:\n",
    "        green_comm_inds_train.append(comms_training.index(tmp))\n",
    "    else:\n",
    "        green_comm_inds_val.append(comms_validation.index(tmp))\n",
    "\n",
    "\n",
    "purple_comm_inds_train, purple_comm_inds_val = [], []\n",
    "for ind in purple_comm:\n",
    "    tmp = orderlist[ind]\n",
    "    if tmp in comms_training:\n",
    "        purple_comm_inds_train.append(comms_training.index(tmp))\n",
    "    else:\n",
    "        purple_comm_inds_val.append(comms_validation.index(tmp))\n",
    "\n",
    "\n",
    "orange_comm_inds_train, orange_comm_inds_val = [], []\n",
    "for ind in orange_comm:\n",
    "    tmp = orderlist[ind]\n",
    "    if tmp in comms_training:\n",
    "        orange_comm_inds_train.append(comms_training.index(tmp))\n",
    "    else:\n",
    "        orange_comm_inds_val.append(comms_validation.index(tmp))\n",
    "        \n",
    "        \n",
    "grey_comm_inds_train, grey_comm_inds_val = [], []\n",
    "for ind in grey_comm:\n",
    "    tmp = orderlist[ind]\n",
    "    if tmp in comms_training:\n",
    "        grey_comm_inds_train.append(comms_training.index(tmp))\n",
    "    else:\n",
    "        grey_comm_inds_val.append(comms_validation.index(tmp))\n",
    "        \n",
    "        \n",
    "red_comm_x    = torch.cat((x_train[red_comm_inds_train],x_test[red_comm_inds_val]),dim=0)\n",
    "red_comm_y    = torch.cat((y_train[red_comm_inds_train],y_test[red_comm_inds_val]),dim=0)\n",
    "\n",
    "blue_comm_x   = torch.cat((x_train[blue_comm_inds_train],x_test[blue_comm_inds_val]),dim=0)\n",
    "blue_comm_y   = torch.cat((y_train[blue_comm_inds_train],y_test[blue_comm_inds_val]),dim=0)\n",
    "\n",
    "green_comm_x  = torch.cat((x_train[green_comm_inds_train],x_test[green_comm_inds_val]),dim=0)\n",
    "green_comm_y  = torch.cat((y_train[green_comm_inds_train],y_test[green_comm_inds_val]),dim=0)\n",
    "\n",
    "purple_comm_x = torch.cat((x_train[purple_comm_inds_train],x_test[purple_comm_inds_val]),dim=0)\n",
    "purple_comm_y = torch.cat((y_train[purple_comm_inds_train],y_test[purple_comm_inds_val]),dim=0)\n",
    "\n",
    "orange_comm_x = torch.cat((x_train[orange_comm_inds_train],x_test[orange_comm_inds_val]),dim=0)\n",
    "orange_comm_y = torch.cat((y_train[orange_comm_inds_train],y_test[orange_comm_inds_val]),dim=0)\n",
    "\n",
    "grey_comm_x   = torch.cat((x_train[grey_comm_inds_train],x_test[grey_comm_inds_val]),dim=0)\n",
    "grey_comm_y   = torch.cat((y_train[grey_comm_inds_train],y_test[grey_comm_inds_val]),dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abundance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_to_study in range(seq_len):\n",
    "    Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "    Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "    model.eval()\n",
    "    actual, predicted = [], []\n",
    "    \n",
    "    for x_batch, y_batch, batch in generate_batch_data(red_comm_x[:,0:1,:], red_comm_y, batch_size):\n",
    "        y_pred     = model(x_batch, future=seq_len-1)\n",
    "        y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "        actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        plt_str    = 'Red Community'\n",
    "\n",
    "    act_arr  = np.array(actual)\n",
    "    pred_arr = np.array(predicted)\n",
    "\n",
    "    Act  = (act_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred = (pred_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred[Pred<0] = 0.\n",
    "\n",
    "    slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "\n",
    "    print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "    x_vals = np.linspace(min(Act),max(Act),50)\n",
    "    y_vals = slope*x_vals + intercept\n",
    "\n",
    "    params = {'legend.fontsize': 24,\n",
    "              'figure.figsize' : (10, 10),\n",
    "             'axes.labelsize'  : 24,\n",
    "             'axes.titlesize'  : 24,\n",
    "             'xtick.labelsize' : 22,\n",
    "             'ytick.labelsize' : 22,\n",
    "             'pdf.fonttype'    : 42}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "    plt.plot(Act, Pred, 'or')\n",
    "    plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "    plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.legend(['Predicted abundance','Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "    plt.savefig('output/Community/Abundance/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_to_study in range(seq_len):\n",
    "    Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "    Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "    model.eval()\n",
    "    actual, predicted = [], []\n",
    "    \n",
    "    for x_batch, y_batch, batch in generate_batch_data(blue_comm_x[:,0:1,:], blue_comm_y, batch_size):\n",
    "        y_pred     = model(x_batch, future=seq_len-1)\n",
    "        y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "        actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        plt_str    = 'Blue Community'\n",
    "\n",
    "    act_arr  = np.array(actual)\n",
    "    pred_arr = np.array(predicted)\n",
    "    \n",
    "    Act  = (act_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred = (pred_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred[Pred<0] = 0.\n",
    "    \n",
    "    slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "    print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "    x_vals = np.linspace(min(Act),max(Act),50)\n",
    "    y_vals = slope*x_vals + intercept\n",
    "\n",
    "    params = {'legend.fontsize': 24,\n",
    "              'figure.figsize' : (10, 10),\n",
    "             'axes.labelsize'  : 24,\n",
    "             'axes.titlesize'  : 24,\n",
    "             'xtick.labelsize' : 22,\n",
    "             'ytick.labelsize' : 22,\n",
    "             'pdf.fonttype'    : 42}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "    plt.plot(Act, Pred, 'or')\n",
    "    plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "    plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.legend(['Predicted abundance','Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "    plt.savefig('output/Community/Abundance/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_to_study in range(seq_len):\n",
    "    Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "    Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "    model.eval()\n",
    "    actual, predicted = [], []\n",
    "    \n",
    "    for x_batch, y_batch, batch in generate_batch_data(green_comm_x[:,0:1,:], green_comm_y, batch_size):\n",
    "        y_pred     = model(x_batch, future=seq_len-1)\n",
    "        y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "        actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        plt_str    = 'Green Community'\n",
    "\n",
    "    act_arr  = np.array(actual)\n",
    "    pred_arr = np.array(predicted)\n",
    "\n",
    "    Act  = (act_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred = (pred_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred[Pred<0] = 0.\n",
    "\n",
    "    slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "    print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "    x_vals = np.linspace(min(Act),max(Act),50)\n",
    "    y_vals = slope*x_vals + intercept\n",
    "\n",
    "    params = {'legend.fontsize': 24,\n",
    "              'figure.figsize' : (10, 10),\n",
    "             'axes.labelsize'  : 24,\n",
    "             'axes.titlesize'  : 24,\n",
    "             'xtick.labelsize' : 22,\n",
    "             'ytick.labelsize' : 22,\n",
    "             'pdf.fonttype'    : 42}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "    plt.plot(Act, Pred, 'or')\n",
    "    plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "    plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.legend(['Predicted abundance','Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "    plt.savefig('output/Community/Abundance/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_to_study in range(seq_len):\n",
    "    Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "    Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "    model.eval()\n",
    "    actual, predicted = [], []\n",
    "    \n",
    "    for x_batch, y_batch, batch in generate_batch_data(purple_comm_x[:,0:1,:], purple_comm_y, batch_size):\n",
    "        y_pred     = model(x_batch, future=seq_len-1)\n",
    "        y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "        actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        plt_str    = 'Purple Community'\n",
    "    \n",
    "    act_arr  = np.array(actual)\n",
    "    pred_arr = np.array(predicted)\n",
    "    \n",
    "    Act  = (act_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred = (pred_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred[Pred<0] = 0.\n",
    "\n",
    "    slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "    print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "    x_vals = np.linspace(min(Act),max(Act),50)\n",
    "    y_vals = slope*x_vals + intercept\n",
    "\n",
    "    params = {'legend.fontsize': 24,\n",
    "              'figure.figsize' : (10, 10),\n",
    "             'axes.labelsize'  : 24,\n",
    "             'axes.titlesize'  : 24,\n",
    "             'xtick.labelsize' : 22,\n",
    "             'ytick.labelsize' : 22,\n",
    "             'pdf.fonttype'    : 42}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "    plt.plot(Act, Pred, 'or')\n",
    "    plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "    plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.legend(['Predicted abundance','Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "    plt.savefig('output/Community/Abundance/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_to_study in range(seq_len):\n",
    "    Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "    Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "    model.eval()\n",
    "    actual, predicted = [], []\n",
    "    \n",
    "    for x_batch, y_batch, batch in generate_batch_data(orange_comm_x[:,0:1,:], orange_comm_y, batch_size):\n",
    "        y_pred     = model(x_batch, future=seq_len-1)\n",
    "        y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "        actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        plt_str    = 'Orange Community'\n",
    "\n",
    "    act_arr  = np.array(actual)\n",
    "    pred_arr = np.array(predicted)\n",
    "\n",
    "    Act  = (act_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred = (pred_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred[Pred<0] = 0.\n",
    "\n",
    "    slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "    print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "    x_vals = np.linspace(min(Act),max(Act),50)\n",
    "    y_vals = slope*x_vals + intercept\n",
    "\n",
    "    params = {'legend.fontsize': 24,\n",
    "              'figure.figsize' : (10, 10),\n",
    "             'axes.labelsize'  : 24,\n",
    "             'axes.titlesize'  : 24,\n",
    "             'xtick.labelsize' : 22,\n",
    "             'ytick.labelsize' : 22,\n",
    "             'pdf.fonttype'    : 42}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "    plt.plot(Act, Pred, 'or')\n",
    "    plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "    plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.legend(['Predicted abundance','Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "    plt.savefig('output/Community/Abundance/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_to_study in range(seq_len):\n",
    "    Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "    Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "    model.eval()\n",
    "    actual, predicted = [], []\n",
    "    \n",
    "    for x_batch, y_batch, batch in generate_batch_data(grey_comm_x[:,0:1,:], grey_comm_y, batch_size):\n",
    "        y_pred     = model(x_batch, future=seq_len-1)\n",
    "        y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "        actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "        plt_str    = 'Grey Community'\n",
    "\n",
    "    act_arr  = np.array(actual)\n",
    "    pred_arr = np.array(predicted)\n",
    "\n",
    "    Act  = (act_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred = (pred_arr[:,:-4]*Xv_[:-4] + Xm_[:-4]).reshape(-1)\n",
    "    Pred[Pred<0] = 0.\n",
    "\n",
    "    slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "    print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "    x_vals = np.linspace(min(Act),max(Act),50)\n",
    "    y_vals = slope*x_vals + intercept\n",
    "\n",
    "    params = {'legend.fontsize': 24,\n",
    "              'figure.figsize' : (10, 10),\n",
    "             'axes.labelsize'  : 24,\n",
    "             'axes.titlesize'  : 24,\n",
    "             'xtick.labelsize' : 22,\n",
    "             'ytick.labelsize' : 22,\n",
    "             'pdf.fonttype'    : 42}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "    plt.plot(Act, Pred, 'or')\n",
    "    plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "    plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.legend(['Predicted abundance','Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "    plt.savefig('output/Community/Abundance/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metabolite concentration prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab_list = ['Butyrate', 'Acetate', 'Lactate', 'Succinate']\n",
    "\n",
    "for no, metab_name in enumerate(metab_list):\n",
    "    metab_ind = no-4\n",
    "    \n",
    "    for ind_to_study in range(seq_len):\n",
    "        Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "        Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "        model.eval()\n",
    "        actual, predicted = [], []\n",
    "\n",
    "        for x_batch, y_batch, batch in generate_batch_data(red_comm_x[:,0:1,:], red_comm_y, batch_size):\n",
    "            y_pred     = model(x_batch, future=seq_len-1)\n",
    "            y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "            actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            plt_str    = 'Red Community - ' + metab_name\n",
    "\n",
    "        act_arr  = np.array(actual)\n",
    "        pred_arr = np.array(predicted)\n",
    "\n",
    "        Act  = (act_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred = (pred_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred[Pred<0] = 0.\n",
    "\n",
    "        slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "        print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "        x_vals = np.linspace(min(Act),max(Act),50)\n",
    "        y_vals = slope*x_vals + intercept\n",
    "\n",
    "        params = {'legend.fontsize': 24,\n",
    "                  'figure.figsize' : (10, 10),\n",
    "                 'axes.labelsize'  : 24,\n",
    "                 'axes.titlesize'  : 24,\n",
    "                 'xtick.labelsize' : 22,\n",
    "                 'ytick.labelsize' : 22,\n",
    "                 'pdf.fonttype'    : 42}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "        plt.plot(Act, Pred, 'or')\n",
    "        plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "        plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "        plt.xlabel('True values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.legend(['Predicted concentration_' + metab_name,'Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "        plt.savefig('output/Community/Metabolites/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab_list = ['Butyrate', 'Acetate', 'Lactate', 'Succinate']\n",
    "\n",
    "for no, metab_name in enumerate(metab_list):\n",
    "    metab_ind = no-4\n",
    "    \n",
    "    for ind_to_study in range(seq_len):\n",
    "        Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "        Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "        model.eval()\n",
    "        actual, predicted = [], []\n",
    "\n",
    "        for x_batch, y_batch, batch in generate_batch_data(blue_comm_x[:,0:1,:], blue_comm_y, batch_size):\n",
    "            y_pred     = model(x_batch, future=seq_len-1)\n",
    "            y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "            actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            plt_str    = 'Blue Community - ' + metab_name\n",
    "\n",
    "        act_arr  = np.array(actual)\n",
    "        pred_arr = np.array(predicted)\n",
    "\n",
    "        Act  = (act_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred = (pred_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred[Pred<0] = 0.\n",
    "\n",
    "        slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "        print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "        x_vals = np.linspace(min(Act),max(Act),50)\n",
    "        y_vals = slope*x_vals + intercept\n",
    "\n",
    "        params = {'legend.fontsize': 24,\n",
    "                  'figure.figsize' : (10, 10),\n",
    "                 'axes.labelsize'  : 24,\n",
    "                 'axes.titlesize'  : 24,\n",
    "                 'xtick.labelsize' : 22,\n",
    "                 'ytick.labelsize' : 22,\n",
    "                 'pdf.fonttype'    : 42}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "        plt.plot(Act, Pred, 'or')\n",
    "        plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "        plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "        plt.xlabel('True values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.legend(['Predicted concentration_' + metab_name,'Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "        plt.savefig('output/Community/Metabolites/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab_list = ['Butyrate', 'Acetate', 'Lactate', 'Succinate']\n",
    "\n",
    "for no, metab_name in enumerate(metab_list):\n",
    "    metab_ind = no-4\n",
    "    \n",
    "    for ind_to_study in range(seq_len):\n",
    "        Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "        Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "        model.eval()\n",
    "        actual, predicted = [], []\n",
    "\n",
    "        for x_batch, y_batch, batch in generate_batch_data(green_comm_x[:,0:1,:], green_comm_y, batch_size):\n",
    "            y_pred     = model(x_batch, future=seq_len-1)\n",
    "            y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "            actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            plt_str    = 'Green Community - ' + metab_name\n",
    "\n",
    "        act_arr  = np.array(actual)\n",
    "        pred_arr = np.array(predicted)\n",
    "\n",
    "        Act  = (act_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred = (pred_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred[Pred<0] = 0.\n",
    "\n",
    "        slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "        print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "        x_vals = np.linspace(min(Act),max(Act),50)\n",
    "        y_vals = slope*x_vals + intercept\n",
    "\n",
    "        params = {'legend.fontsize': 24,\n",
    "                  'figure.figsize' : (10, 10),\n",
    "                 'axes.labelsize'  : 24,\n",
    "                 'axes.titlesize'  : 24,\n",
    "                 'xtick.labelsize' : 22,\n",
    "                 'ytick.labelsize' : 22,\n",
    "                 'pdf.fonttype'    : 42}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "        plt.plot(Act, Pred, 'or')\n",
    "        plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "        plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "        plt.xlabel('True values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.legend(['Predicted concentration_' + metab_name,'Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "        plt.savefig('output/Community/Metabolites/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab_list = ['Butyrate', 'Acetate', 'Lactate', 'Succinate']\n",
    "\n",
    "for no, metab_name in enumerate(metab_list):\n",
    "    metab_ind = no-4\n",
    "    \n",
    "    for ind_to_study in range(seq_len):\n",
    "        Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "        Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "        model.eval()\n",
    "        actual, predicted = [], []\n",
    "\n",
    "        for x_batch, y_batch, batch in generate_batch_data(purple_comm_x[:,0:1,:], purple_comm_y, batch_size):\n",
    "            y_pred     = model(x_batch, future=seq_len-1)\n",
    "            y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "            actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            plt_str    = 'Purple Community - ' + metab_name\n",
    "\n",
    "        act_arr  = np.array(actual)\n",
    "        pred_arr = np.array(predicted)\n",
    "\n",
    "        Act  = (act_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred = (pred_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred[Pred<0] = 0.\n",
    "\n",
    "        slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "        print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "        x_vals = np.linspace(min(Act),max(Act),50)\n",
    "        y_vals = slope*x_vals + intercept\n",
    "\n",
    "        params = {'legend.fontsize': 24,\n",
    "                  'figure.figsize' : (10, 10),\n",
    "                 'axes.labelsize'  : 24,\n",
    "                 'axes.titlesize'  : 24,\n",
    "                 'xtick.labelsize' : 22,\n",
    "                 'ytick.labelsize' : 22,\n",
    "                 'pdf.fonttype'    : 42}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "        plt.plot(Act, Pred, 'or')\n",
    "        plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "        plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "        plt.xlabel('True values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.legend(['Predicted concentration_' + metab_name,'Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "        plt.savefig('output/Community/Metabolites/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab_list = ['Butyrate', 'Acetate', 'Lactate', 'Succinate']\n",
    "\n",
    "for no, metab_name in enumerate(metab_list):\n",
    "    metab_ind = no-4\n",
    "    \n",
    "    for ind_to_study in range(seq_len):\n",
    "        Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "        Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "        model.eval()\n",
    "        actual, predicted = [], []\n",
    "\n",
    "        for x_batch, y_batch, batch in generate_batch_data(orange_comm_x[:,0:1,:], orange_comm_y, batch_size):\n",
    "            y_pred     = model(x_batch, future=seq_len-1)\n",
    "            y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "            actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            plt_str    = 'Orange Community - ' + metab_name\n",
    "\n",
    "        act_arr  = np.array(actual)\n",
    "        pred_arr = np.array(predicted)\n",
    "\n",
    "        Act  = (act_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred = (pred_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred[Pred<0] = 0.\n",
    "\n",
    "        slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "        print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "        x_vals = np.linspace(min(Act),max(Act),50)\n",
    "        y_vals = slope*x_vals + intercept\n",
    "\n",
    "        params = {'legend.fontsize': 24,\n",
    "                  'figure.figsize' : (10, 10),\n",
    "                 'axes.labelsize'  : 24,\n",
    "                 'axes.titlesize'  : 24,\n",
    "                 'xtick.labelsize' : 22,\n",
    "                 'ytick.labelsize' : 22,\n",
    "                 'pdf.fonttype'    : 42}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "        plt.plot(Act, Pred, 'or')\n",
    "        plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "        plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "        plt.xlabel('True values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.legend(['Predicted concentration_' + metab_name,'Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "        plt.savefig('output/Community/Metabolites/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab_list = ['Butyrate', 'Acetate', 'Lactate', 'Succinate']\n",
    "\n",
    "for no, metab_name in enumerate(metab_list):\n",
    "    metab_ind = no-4\n",
    "    \n",
    "    for ind_to_study in range(seq_len):\n",
    "        Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "        Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "        model.eval()\n",
    "        actual, predicted = [], []\n",
    "\n",
    "        for x_batch, y_batch, batch in generate_batch_data(grey_comm_x[:,0:1,:], grey_comm_y, batch_size):\n",
    "            y_pred     = model(x_batch, future=seq_len-1)\n",
    "            y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "            actual    += torch.squeeze(y_batch[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            predicted += torch.squeeze(y_pred[:, ind_to_study]).data.cpu().numpy().reshape(y_pred.size(0),-1).tolist()\n",
    "            plt_str    = 'Grey Community - ' + metab_name\n",
    "\n",
    "        act_arr  = np.array(actual)\n",
    "        pred_arr = np.array(predicted)\n",
    "\n",
    "        Act  = (act_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred = (pred_arr[:,metab_ind]*Xv_[metab_ind] + Xm_[metab_ind]).reshape(-1)\n",
    "        Pred[Pred<0] = 0.\n",
    "\n",
    "        slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "        \n",
    "        print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "        x_vals = np.linspace(min(Act),max(Act),50)\n",
    "        y_vals = slope*x_vals + intercept\n",
    "\n",
    "        params = {'legend.fontsize': 24,\n",
    "                  'figure.figsize' : (10, 10),\n",
    "                 'axes.labelsize'  : 24,\n",
    "                 'axes.titlesize'  : 24,\n",
    "                 'xtick.labelsize' : 22,\n",
    "                 'ytick.labelsize' : 22,\n",
    "                 'pdf.fonttype'    : 42}\n",
    "        plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "        plt.plot(Act, Pred, 'or')\n",
    "        plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "        plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('square')\n",
    "        plt.title(plt_str+' set: At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "        plt.xlabel('True values')\n",
    "        plt.ylabel('Predicted values')\n",
    "        plt.legend(['Predicted concentration_' + metab_name,'Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "        plt.savefig('output/Community/Metabolites/'+plt_str+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing heat maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Butyrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "buty_grad_list = {}\n",
    "\n",
    "Xm__      = torch.tensor(Xm_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "Xv__      = torch.tensor(Xv_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "\n",
    "met_ind   = 25\n",
    "\n",
    "for ind_to_study in range(seq_len):\n",
    "\n",
    "    buty_grad_list[ind_to_study] = []\n",
    "    \n",
    "    for b in range(x_test.size(0)):\n",
    "        model.eval()\n",
    "        inp        = Variable(x_test[b:b+1,0:1,:],requires_grad=True)\n",
    "        y_pred     = model(inp, future=seq_len-1)\n",
    "        \n",
    "        x_ini      = torch.squeeze(torch.squeeze(x_test[b:b+1,0:1,:]*Xv__ + Xm__,1),0).to('cpu').data.numpy()\n",
    "        mask       = np.ones((25,))\n",
    "        mask[x_ini[:25]<1e-6] = 0.\n",
    "        \n",
    "        y_pred[0,ind_to_study,met_ind].backward()\n",
    "        grad_data = inp.grad.data\n",
    "        \n",
    "        buty_grad_list[ind_to_study].append((grad_data.to('cpu').numpy()[0,0,:25]*mask).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = []\n",
    "\n",
    "hm.append((Xv_abun_metab[0][:25]/Xv_abun_metab[0][met_ind])*buty_grad_list[0][-1])\n",
    "hm.append((Xv_abun_metab[1][:25]/Xv_abun_metab[1][met_ind])*buty_grad_list[1][-1])\n",
    "hm.append((Xv_abun_metab[2][:25]/Xv_abun_metab[2][met_ind])*buty_grad_list[2][-1])\n",
    "\n",
    "params = {'legend.fontsize': 24,\n",
    "          'figure.figsize' : (10, 10),\n",
    "         'axes.labelsize'  : 24,\n",
    "         'axes.titlesize'  : 24,\n",
    "         'xtick.labelsize' : 22,\n",
    "         'ytick.labelsize' : 22,\n",
    "         'pdf.fonttype'    : 42}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(25, 5))\n",
    "x_axis_labels = ['PC','PJ','BV','BF','BO','BT','BC','BY','BU','DP','BL','BA','BP','CA','EL','FP','CH','AC','BH','CG','ER','RI','CC','DL','DF']\n",
    "y_axis_labels = [16, 32, 48]\n",
    "\n",
    "abs_v = np.max(np.array(hm))\n",
    "ax.set_title('Butyrate')\n",
    "ax = sns.heatmap(np.array(hm), xticklabels=x_axis_labels, yticklabels=y_axis_labels, cmap=\"bwr\", vmin=-abs_v, vmax=abs_v)\n",
    "plt.savefig('output/heatmap/butyrate.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acetate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace_grad_list = {}\n",
    "\n",
    "Xm__      = torch.tensor(Xm_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "Xv__      = torch.tensor(Xv_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "\n",
    "met_ind   = 26\n",
    "\n",
    "for ind_to_study in range(seq_len):\n",
    "\n",
    "    ace_grad_list[ind_to_study] = []\n",
    "    \n",
    "    for b in range(x_test.size(0)):\n",
    "        model.eval()\n",
    "        inp        = Variable(x_test[b:b+1,0:1,:],requires_grad=True)\n",
    "        y_pred     = model(inp, future=seq_len-1)\n",
    "        \n",
    "        x_ini      = torch.squeeze(torch.squeeze(x_test[b:b+1,0:1,:]*Xv__ + Xm__,1),0).to('cpu').data.numpy()\n",
    "        mask       = np.ones((25,))\n",
    "        mask[x_ini[:25]<1e-6] = 0.\n",
    "        \n",
    "        y_pred[0,ind_to_study,met_ind].backward()\n",
    "        grad_data = inp.grad.data\n",
    "        \n",
    "        ace_grad_list[ind_to_study].append((grad_data.to('cpu').numpy()[0,0,:25]*mask).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = []\n",
    "\n",
    "hm.append((Xv_abun_metab[0][:25]/Xv_abun_metab[0][met_ind])*ace_grad_list[0][-1])\n",
    "hm.append((Xv_abun_metab[1][:25]/Xv_abun_metab[1][met_ind])*ace_grad_list[1][-1])\n",
    "hm.append((Xv_abun_metab[2][:25]/Xv_abun_metab[2][met_ind])*ace_grad_list[2][-1])\n",
    "\n",
    "params = {'legend.fontsize': 24,\n",
    "          'figure.figsize' : (10, 10),\n",
    "         'axes.labelsize'  : 24,\n",
    "         'axes.titlesize'  : 24,\n",
    "         'xtick.labelsize' : 22,\n",
    "         'ytick.labelsize' : 22,\n",
    "         'pdf.fonttype'    : 42}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(25, 5))\n",
    "x_axis_labels = ['PC','PJ','BV','BF','BO','BT','BC','BY','BU','DP','BL','BA','BP','CA','EL','FP','CH','AC','BH','CG','ER','RI','CC','DL','DF']\n",
    "y_axis_labels = [16, 32, 48]\n",
    "\n",
    "abs_v = np.max(np.array(hm))\n",
    "ax.set_title('Acetate')\n",
    "ax = sns.heatmap(np.array(hm), xticklabels=x_axis_labels, yticklabels=y_axis_labels, cmap=\"bwr\", vmin=-abs_v, vmax=abs_v)\n",
    "plt.savefig('output/heatmap/acetate.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lactate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lac_grad_list = {}\n",
    "\n",
    "Xm__      = torch.tensor(Xm_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "Xv__      = torch.tensor(Xv_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "\n",
    "met_ind   = 27\n",
    "\n",
    "for ind_to_study in range(seq_len):\n",
    "\n",
    "    lac_grad_list[ind_to_study] = []\n",
    "    \n",
    "    for b in range(x_test.size(0)):\n",
    "        model.eval()\n",
    "        inp        = Variable(x_test[b:b+1,0:1,:],requires_grad=True)\n",
    "        y_pred     = model(inp, future=seq_len-1)\n",
    "        \n",
    "        x_ini      = torch.squeeze(torch.squeeze(x_test[b:b+1,0:1,:]*Xv__ + Xm__,1),0).to('cpu').data.numpy()\n",
    "        mask       = np.ones((25,))\n",
    "        mask[x_ini[:25]<1e-6] = 0.\n",
    "        \n",
    "        y_pred[0,ind_to_study,met_ind].backward()\n",
    "        grad_data = inp.grad.data\n",
    "        \n",
    "        lac_grad_list[ind_to_study].append((grad_data.to('cpu').numpy()[0,0,:25]*mask).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = []\n",
    "\n",
    "hm.append((Xv_abun_metab[0][:25]/Xv_abun_metab[0][met_ind])*lac_grad_list[0][-1])\n",
    "hm.append((Xv_abun_metab[1][:25]/Xv_abun_metab[1][met_ind])*lac_grad_list[1][-1])\n",
    "hm.append((Xv_abun_metab[2][:25]/Xv_abun_metab[2][met_ind])*lac_grad_list[2][-1])\n",
    "\n",
    "params = {'legend.fontsize': 24,\n",
    "          'figure.figsize' : (10, 10),\n",
    "         'axes.labelsize'  : 24,\n",
    "         'axes.titlesize'  : 24,\n",
    "         'xtick.labelsize' : 22,\n",
    "         'ytick.labelsize' : 22,\n",
    "         'pdf.fonttype'    : 42}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(25, 5))\n",
    "x_axis_labels = ['PC','PJ','BV','BF','BO','BT','BC','BY','BU','DP','BL','BA','BP','CA','EL','FP','CH','AC','BH','CG','ER','RI','CC','DL','DF']\n",
    "y_axis_labels = [16, 32, 48]\n",
    "\n",
    "abs_v = np.max(np.array(hm))\n",
    "ax.set_title('Lactate')\n",
    "ax = sns.heatmap(np.array(hm), xticklabels=x_axis_labels, yticklabels=y_axis_labels, cmap=\"bwr\", vmin=-abs_v, vmax=abs_v)\n",
    "plt.savefig('output/heatmap/lactate.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Succinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ_grad_list = {}\n",
    "\n",
    "Xm__      = torch.tensor(Xm_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "Xv__      = torch.tensor(Xv_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "\n",
    "met_ind   = 28\n",
    "\n",
    "for ind_to_study in range(seq_len):\n",
    "\n",
    "    succ_grad_list[ind_to_study] = []\n",
    "    \n",
    "    for b in range(x_test.size(0)):\n",
    "        model.eval()\n",
    "        inp        = Variable(x_test[b:b+1,0:1,:],requires_grad=True)\n",
    "        y_pred     = model(inp, future=seq_len-1)\n",
    "        \n",
    "        x_ini      = torch.squeeze(torch.squeeze(x_test[b:b+1,0:1,:]*Xv__ + Xm__,1),0).to('cpu').data.numpy()\n",
    "        mask       = np.ones((25,))\n",
    "        mask[x_ini[:25]<1e-6] = 0.\n",
    "        \n",
    "        y_pred[0,ind_to_study,met_ind].backward()\n",
    "        grad_data = inp.grad.data\n",
    "        \n",
    "        succ_grad_list[ind_to_study].append((grad_data.to('cpu').numpy()[0,0,:25]*mask).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = []\n",
    "\n",
    "hm.append((Xv_abun_metab[0][:25]/Xv_abun_metab[0][met_ind])*succ_grad_list[0][-1])\n",
    "hm.append((Xv_abun_metab[1][:25]/Xv_abun_metab[1][met_ind])*succ_grad_list[1][-1])\n",
    "hm.append((Xv_abun_metab[2][:25]/Xv_abun_metab[2][met_ind])*succ_grad_list[2][-1])\n",
    "\n",
    "params = {'legend.fontsize': 24,\n",
    "          'figure.figsize' : (10, 10),\n",
    "         'axes.labelsize'  : 24,\n",
    "         'axes.titlesize'  : 24,\n",
    "         'xtick.labelsize' : 22,\n",
    "         'ytick.labelsize' : 22,\n",
    "         'pdf.fonttype'    : 42}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(25, 5))\n",
    "x_axis_labels = ['PC','PJ','BV','BF','BO','BT','BC','BY','BU','DP','BL','BA','BP','CA','EL','FP','CH','AC','BH','CG','ER','RI','CC','DL','DF']\n",
    "y_axis_labels = [16, 32, 48]\n",
    "\n",
    "abs_v = np.max(np.array(hm))\n",
    "ax.set_title('Succinate')\n",
    "ax = sns.heatmap(np.array(hm), xticklabels=x_axis_labels, yticklabels=y_axis_labels, cmap=\"bwr\", vmin=-abs_v, vmax=abs_v)\n",
    "plt.savefig('output/heatmap/succinate.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Species-wise prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_list = ['PC', 'PJ', 'BV', 'BF', 'BO', 'BT', \\\n",
    "           'BC', 'BY', 'BU', 'DP', 'BL', 'BA', \\\n",
    "           'BP', 'CA', 'EL', 'FP', 'CH', 'AC', \\\n",
    "           'BH', 'CG', 'ER', 'RI', 'CC', 'DL', 'DF']\n",
    "\n",
    "for sp_ind, sp in enumerate(sp_list):\n",
    "    for ind_to_study in range(seq_len):\n",
    "        for is_train in list([True, False]):\n",
    "\n",
    "            Xm_ = Xm_abun_metab[ind_to_study+1]\n",
    "            Xv_ = Xv_abun_metab[ind_to_study+1]\n",
    "\n",
    "            model.eval()\n",
    "            actual, predicted = [], []\n",
    "\n",
    "            if is_train:\n",
    "                for x_batch, y_batch, batch in generate_batch_data(x_train[:,0:1,:], y_train, batch_size):\n",
    "                    inds_inc   = np.where(abs((x_batch[:,0,sp_ind]*Xv_abun_metab[0,sp_ind] + Xm_abun_metab[0,sp_ind]).to('cpu').data.numpy())>1e-5)[0]\n",
    "                    y_pred     = model(x_batch, future=seq_len-1)\n",
    "                    y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "                    \n",
    "                    if len(inds_inc) > 0:\n",
    "                        actual    += y_batch[inds_inc, ind_to_study, sp_ind].data.cpu().numpy().tolist()\n",
    "                        predicted += y_pred[inds_inc, ind_to_study, sp_ind].data.cpu().numpy().tolist()\n",
    "                        plt_str    = 'Training'\n",
    "            else:\n",
    "                for x_batch, y_batch, batch in generate_batch_data(x_test[:,0:1,:], y_test, batch_size):\n",
    "                    inds_inc   = np.where(abs((x_batch[:,0,sp_ind]*Xv_abun_metab[0,sp_ind] + Xm_abun_metab[0,sp_ind]).to('cpu').data.numpy())>1e-5)[0]\n",
    "                    y_pred     = model(x_batch, future=seq_len-1)\n",
    "                    y_pred     = (y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred)\n",
    "                    \n",
    "                    if len(inds_inc) > 0:\n",
    "                        actual    += y_batch[inds_inc, ind_to_study, sp_ind].data.cpu().numpy().tolist()\n",
    "                        predicted += y_pred[inds_inc, ind_to_study, sp_ind].data.cpu().numpy().tolist()\n",
    "                        plt_str    = 'Testing'\n",
    "\n",
    "            act_arr  = np.array(actual)\n",
    "            pred_arr = np.array(predicted)\n",
    "\n",
    "            Act  = (act_arr*Xv_[sp_ind] + Xm_[sp_ind]).reshape(-1)\n",
    "            Pred = (pred_arr*Xv_[sp_ind] + Xm_[sp_ind]).reshape(-1)\n",
    "            Pred[Pred<0] = 0.\n",
    "\n",
    "            slope, intercept, r, p, se = stats.linregress(Act, Pred)\n",
    "\n",
    "            print('Coefficient of determination: %.2f' %(r**2))\n",
    "\n",
    "            x_vals = np.linspace(min(Act),max(Act),50)\n",
    "            y_vals = slope*x_vals + intercept\n",
    "\n",
    "            params = {'legend.fontsize': 24,\n",
    "                      'figure.figsize' : (10, 10),\n",
    "                     'axes.labelsize'  : 24,\n",
    "                     'axes.titlesize'  : 24,\n",
    "                     'xtick.labelsize' : 22,\n",
    "                     'ytick.labelsize' : 22,\n",
    "                     'pdf.fonttype'    : 42}\n",
    "            plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "            plt.plot(Act, Pred, 'or')\n",
    "            plt.plot(x_vals, y_vals, color='black', linewidth = 3)\n",
    "            plt.plot(x_vals, x_vals, '--b', linewidth = 3)\n",
    "            plt.axis('equal')\n",
    "            plt.axis('square')\n",
    "            plt.title(plt_str+' set ('+sp+'): At t = '+str(int((1+ind_to_study)*16)) + ' hrs')\n",
    "            plt.xlabel('True values')\n",
    "            plt.ylabel('Predicted values')\n",
    "            plt.legend(['Predicted abundance','Linear fit: slope = ' + format(slope,'.2f') + ', R2: ' + format(r**2,'.2f'),'unity slope'])\n",
    "            plt.savefig('output/Abundance/'+plt_str+'_'+sp+'_'+str(int((ind_to_study+1)*16))+'.pdf')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community-wise heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grey community heatmaps (Sample code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buty_grad_list = {}\n",
    "ace_grad_list  = {}\n",
    "lac_grad_list  = {}\n",
    "succ_grad_list = {}\n",
    "\n",
    "Xm__      = torch.tensor(Xm_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "Xv__      = torch.tensor(Xv_abun_metab[0,:].reshape(1,1,-1)).to(device)\n",
    "\n",
    "met_ind   = 25\n",
    "for ind_to_study in range(seq_len):\n",
    "    buty_grad_list[ind_to_study] = []\n",
    "    for b in range(grey_comm_x.size(0)):\n",
    "        model.eval()\n",
    "        inp        = Variable(grey_comm_x[b:b+1,0:1,:],requires_grad=True)\n",
    "        y_pred     = model(inp, future=seq_len-1)\n",
    "        \n",
    "        x_ini      = torch.squeeze(torch.squeeze(grey_comm_x[b:b+1,0:1,:]*Xv__ + Xm__,1),0).to('cpu').data.numpy()\n",
    "        mask       = np.ones((25,))\n",
    "        mask[x_ini[:25]<1e-6] = 0.\n",
    "        \n",
    "        y_pred[0,ind_to_study,met_ind].backward()\n",
    "        grad_data = inp.grad.data\n",
    "        \n",
    "        buty_grad_list[ind_to_study].append((grad_data.to('cpu').numpy()[0,0,:25]*mask).tolist())\n",
    "        \n",
    "        \n",
    "met_ind   = 26\n",
    "for ind_to_study in range(seq_len):\n",
    "    ace_grad_list[ind_to_study] = []\n",
    "    for b in range(grey_comm_x.size(0)):\n",
    "        model.eval()\n",
    "        inp        = Variable(grey_comm_x[b:b+1,0:1,:],requires_grad=True)\n",
    "        y_pred     = model(inp, future=seq_len-1)\n",
    "        \n",
    "        x_ini      = torch.squeeze(torch.squeeze(grey_comm_x[b:b+1,0:1,:]*Xv__ + Xm__,1),0).to('cpu').data.numpy()\n",
    "        mask       = np.ones((25,))\n",
    "        mask[x_ini[:25]<1e-6] = 0.\n",
    "        \n",
    "        y_pred[0,ind_to_study,met_ind].backward()\n",
    "        grad_data = inp.grad.data\n",
    "        \n",
    "        ace_grad_list[ind_to_study].append((grad_data.to('cpu').numpy()[0,0,:25]*mask).tolist())\n",
    "        \n",
    "        \n",
    "met_ind   = 27\n",
    "for ind_to_study in range(seq_len):\n",
    "    lac_grad_list[ind_to_study] = []\n",
    "    for b in range(grey_comm_x.size(0)):\n",
    "        model.eval()\n",
    "        inp        = Variable(grey_comm_x[b:b+1,0:1,:],requires_grad=True)\n",
    "        y_pred     = model(inp, future=seq_len-1)\n",
    "        \n",
    "        x_ini      = torch.squeeze(torch.squeeze(grey_comm_x[b:b+1,0:1,:]*Xv__ + Xm__,1),0).to('cpu').data.numpy()\n",
    "        mask       = np.ones((25,))\n",
    "        mask[x_ini[:25]<1e-6] = 0.\n",
    "        \n",
    "        y_pred[0,ind_to_study,met_ind].backward()\n",
    "        grad_data = inp.grad.data\n",
    "        \n",
    "        lac_grad_list[ind_to_study].append((grad_data.to('cpu').numpy()[0,0,:25]*mask).tolist())\n",
    "        \n",
    "        \n",
    "met_ind   = 28\n",
    "for ind_to_study in range(seq_len):\n",
    "    succ_grad_list[ind_to_study] = []\n",
    "    for b in range(grey_comm_x.size(0)):\n",
    "        model.eval()\n",
    "        inp        = Variable(grey_comm_x[b:b+1,0:1,:],requires_grad=True)\n",
    "        y_pred     = model(inp, future=seq_len-1)\n",
    "        \n",
    "        x_ini      = torch.squeeze(torch.squeeze(grey_comm_x[b:b+1,0:1,:]*Xv__ + Xm__,1),0).to('cpu').data.numpy()\n",
    "        mask       = np.ones((25,))\n",
    "        mask[x_ini[:25]<1e-6] = 0.\n",
    "        \n",
    "        y_pred[0,ind_to_study,met_ind].backward()\n",
    "        grad_data = inp.grad.data\n",
    "        \n",
    "        succ_grad_list[ind_to_study].append((grad_data.to('cpu').numpy()[0,0,:25]*mask).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output = ('output/heatmap/GreyCommunity/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "for b in range(grey_comm_x.size(0)):\n",
    "    for met_ind in range(25,29):\n",
    "        hm = []\n",
    "        if met_ind == 25:\n",
    "            hm.append((Xv_abun_metab[0][:25]/Xv_abun_metab[0][met_ind])*buty_grad_list[0][b])\n",
    "            hm.append((Xv_abun_metab[1][:25]/Xv_abun_metab[1][met_ind])*buty_grad_list[1][b])\n",
    "            hm.append((Xv_abun_metab[2][:25]/Xv_abun_metab[2][met_ind])*buty_grad_list[2][b])\n",
    "            plt_str = 'Butyrate'\n",
    "        elif met_ind == 26:\n",
    "            hm.append((Xv_abun_metab[0][:25]/Xv_abun_metab[0][met_ind])*ace_grad_list[0][b])\n",
    "            hm.append((Xv_abun_metab[1][:25]/Xv_abun_metab[1][met_ind])*ace_grad_list[1][b])\n",
    "            hm.append((Xv_abun_metab[2][:25]/Xv_abun_metab[2][met_ind])*ace_grad_list[2][b])\n",
    "            plt_str = 'Acetate'\n",
    "        elif met_ind == 27:\n",
    "            hm.append((Xv_abun_metab[0][:25]/Xv_abun_metab[0][met_ind])*lac_grad_list[0][b])\n",
    "            hm.append((Xv_abun_metab[1][:25]/Xv_abun_metab[1][met_ind])*lac_grad_list[1][b])\n",
    "            hm.append((Xv_abun_metab[2][:25]/Xv_abun_metab[2][met_ind])*lac_grad_list[2][b])\n",
    "            plt_str = 'Lactate'\n",
    "        else:\n",
    "            hm.append((Xv_abun_metab[0][:25]/Xv_abun_metab[0][met_ind])*succ_grad_list[0][b])\n",
    "            hm.append((Xv_abun_metab[1][:25]/Xv_abun_metab[1][met_ind])*succ_grad_list[1][b])\n",
    "            hm.append((Xv_abun_metab[2][:25]/Xv_abun_metab[2][met_ind])*succ_grad_list[2][b])\n",
    "            plt_str = 'Succinate'\n",
    "            \n",
    "            \n",
    "        params = {'legend.fontsize': 24,\n",
    "                  'figure.figsize' : (10, 10),\n",
    "                 'axes.labelsize'  : 24,\n",
    "                 'axes.titlesize'  : 24,\n",
    "                 'xtick.labelsize' : 22,\n",
    "                 'ytick.labelsize' : 22,\n",
    "                 'pdf.fonttype'    : 42}\n",
    "        plt.rcParams.update(params)\n",
    "        \n",
    "        f, ax = plt.subplots(figsize=(25, 5))\n",
    "        x_axis_labels = ['PC','PJ','BV','BF','BO','BT','BC','BY','BU','DP','BL','BA','BP','CA','EL','FP','CH','AC','BH','CG','ER','RI','CC','DL','DF']\n",
    "        y_axis_labels = [16, 32, 48]\n",
    "        \n",
    "        abs_v = np.max(np.array(hm))\n",
    "        ax.set_title(plt_str + ': Example '+str(b+1))\n",
    "        ax = sns.heatmap(np.array(hm), xticklabels=x_axis_labels, yticklabels=y_axis_labels, cmap=\"bwr\", vmin=-abs_v, vmax=abs_v)\n",
    "        plt.savefig('output/heatmap/GreyCommunity/example_'+str(b+1)+'_'+plt_str+'.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
